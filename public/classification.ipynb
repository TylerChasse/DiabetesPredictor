{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76889ee5-ca70-41aa-bb2d-d84c7d948102",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a98c23f-f08a-478a-a02f-f256ab804cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e855efb-feeb-49f6-97ae-f7dd26c69f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126839 entries, 0 to 126838\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype\n",
      "---  ------                --------------   -----\n",
      " 0   HeartDiseaseorAttack  126839 non-null  int64\n",
      " 1   HighBP                126839 non-null  int64\n",
      " 2   HighChol              126839 non-null  int64\n",
      " 3   CholCheck             126839 non-null  int64\n",
      " 4   BMI                   126839 non-null  int64\n",
      " 5   Smoker                126839 non-null  int64\n",
      " 6   Stroke                126839 non-null  int64\n",
      " 7   Diabetes              126839 non-null  int64\n",
      " 8   PhysActivity          126839 non-null  int64\n",
      " 9   Fruits                126839 non-null  int64\n",
      " 10  Veggies               126839 non-null  int64\n",
      " 11  HvyAlcoholConsump     126839 non-null  int64\n",
      " 12  AnyHealthcare         126839 non-null  int64\n",
      " 13  NoDocbcCost           126839 non-null  int64\n",
      " 14  GenHlth               126839 non-null  int64\n",
      " 15  MentHlth              126839 non-null  int64\n",
      " 16  PhysHlth              126839 non-null  int64\n",
      " 17  DiffWalk              126839 non-null  int64\n",
      " 18  Sex                   126839 non-null  int64\n",
      " 19  Age                   126839 non-null  int64\n",
      " 20  Education             126839 non-null  int64\n",
      " 21  Income                126839 non-null  int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 21.3 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI',\n",
       "       'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"diabetes_health.csv\")\n",
    "\n",
    "# Display the first 2 rows of the dataset to get a quick look at the data\n",
    "data.head(2)\n",
    "\n",
    "# Generate summary statistics for numerical columns (count, mean, std, min, quartiles, max)\n",
    "data.describe()\n",
    "\n",
    "# Print concise information about the DataFrame: column names, non-null counts, and data types\n",
    "data.info()\n",
    "\n",
    "# Count the number of missing (NaN) values in each column\n",
    "data.isnull().sum()\n",
    "\n",
    "# Display the list of all column names in the dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fdecaec-8f91-492a-bd68-006566b14c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartDiseaseorAttack    0\n",
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "BMI                     0\n",
       "Smoker                  0\n",
       "Stroke                  0\n",
       "Diabetes                0\n",
       "PhysActivity            0\n",
       "Fruits                  0\n",
       "Veggies                 0\n",
       "HvyAlcoholConsump       0\n",
       "AnyHealthcare           0\n",
       "NoDocbcCost             0\n",
       "GenHlth                 0\n",
       "MentHlth                0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Sex                     0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe627dbb-6619-4e14-af05-1209cad3d34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts written: preproc_v1_recall.json, dt_model_v1_recall.json, model_card_v1_recall.md\n"
     ]
    }
   ],
   "source": [
    "import json, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    confusion_matrix, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Helper\n",
    "def to_py(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    if isinstance(o, dict):\n",
    "        return {str(k): to_py(v) for k, v in o.items()}\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        return [to_py(v) for v in o]\n",
    "    return o\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"diabetes_health.csv\")\n",
    "target_col = \"Diabetes\"\n",
    "y = (df[target_col] > 0).astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Split categorical vs numeric\n",
    "categorical_cols, numeric_cols = [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        categorical_cols.append(c)\n",
    "    elif pd.api.types.is_integer_dtype(X[c]):\n",
    "        (categorical_cols if X[c].nunique() <= 10 else numeric_cols).append(c)\n",
    "    else:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "# 2. Train/test split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Preprocessing\n",
    "numeric_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4. Decision Tree tuned for recall\n",
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"dt\", dt)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"dt__max_depth\": [3, 4, 5, 6, None],\n",
    "    \"dt__min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# >>> KEY CHANGE: use recall as primary scoring metric\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=\"recall\", n_jobs=-1\n",
    ")\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_pipe = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# 5. Threshold selection â€” maximize recall subject to F1 floor (optional)\n",
    "val_proba = best_pipe.predict_proba(X_trainval)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_trainval, val_proba)\n",
    "\n",
    "# Choose threshold that achieves max recall with acceptable precision\n",
    "target_min_precision = 0.3  # adjust based on domain\n",
    "mask = prec >= target_min_precision\n",
    "if mask.any():\n",
    "    chosen_idx = np.argmax(rec[mask])  # maximize recall\n",
    "    chosen_threshold = thr[np.where(mask)[0][chosen_idx]]\n",
    "else:\n",
    "    chosen_threshold = 0.3  # fallback default\n",
    "chosen_threshold = float(chosen_threshold)\n",
    "\n",
    "# 6. Evaluate\n",
    "test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_proba >= chosen_threshold).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "    \"pr_auc\": float(average_precision_score(y_test, test_proba)),\n",
    "    \"precision\": float(precision_score(y_test, test_pred)),\n",
    "    \"recall\": float(recall_score(y_test, test_pred)),\n",
    "    \"f1\": float(f1_score(y_test, test_pred))\n",
    "}\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "metrics[\"specificity\"] = float(tn / (tn + fp + 1e-12))\n",
    "metrics[\"confusion_matrix\"] = {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)}\n",
    "\n",
    "# 7. Export artifacts (same as before)\n",
    "preprocessor.fit(X_trainval)\n",
    "num_imputer = preprocessor.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "num_impute_values = {c: float(v) for c, v in zip(numeric_cols, num_imputer.statistics_.tolist())}\n",
    "num_ranges = {c: {\"min\": float(X_trainval[c].min()), \"max\": float(X_trainval[c].max())} for c in numeric_cols}\n",
    "\n",
    "onehot = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_vocabs = {}\n",
    "for c, cats in zip(categorical_cols, onehot.categories_):\n",
    "    cat_vocabs[c] = [None if (isinstance(v, float) and math.isnan(v)) else v for v in cats.tolist()]\n",
    "\n",
    "final_feature_order = []\n",
    "for col in numeric_cols:\n",
    "    final_feature_order.append({\"source\": col, \"kind\": \"numeric\"})\n",
    "for col, cats in cat_vocabs.items():\n",
    "    for cat in cats:\n",
    "        final_feature_order.append({\"source\": col, \"kind\": \"onehot\", \"category\": cat})\n",
    "\n",
    "preproc_manifest = {\n",
    "    \"numeric\": numeric_cols,\n",
    "    \"categorical\": categorical_cols,\n",
    "    \"numeric_imputation\": num_impute_values,\n",
    "    \"numeric_ranges_train\": num_ranges,\n",
    "    \"categorical_vocabulary\": cat_vocabs,\n",
    "    \"final_feature_order\": final_feature_order,\n",
    "    \"preproc_version\": \"v1_recall\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "\n",
    "# 8. Export tree\n",
    "def export_tree(tree_estimator):\n",
    "    tree = tree_estimator.tree_\n",
    "    return {\n",
    "        \"nodes\": [\n",
    "            {\n",
    "                \"feature_index\": int(tree.feature[i]),\n",
    "                \"threshold\": float(tree.threshold[i]),\n",
    "                \"left\": int(tree.children_left[i]),\n",
    "                \"right\": int(tree.children_right[i]),\n",
    "                \"value\": [float(x) for x in tree.value[i][0].tolist()],\n",
    "                \"is_leaf\": bool(tree.children_left[i] == -1 and tree.children_right[i] == -1),\n",
    "            }\n",
    "            for i in range(tree.node_count)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "dt_est = best_pipe.named_steps[\"dt\"]\n",
    "dt_export = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": chosen_threshold,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_version\": \"v1_recall\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "    \"tree\": export_tree(dt_est)\n",
    "}\n",
    "\n",
    "# 9. Model Card\n",
    "model_card = f\"\"\"# Diabetes Decision Tree Model (Recall-Prioritized)\n",
    "\n",
    "**Model version:** v1  \n",
    "**Training date:** {datetime.utcnow().strftime(\"%Y-%m-%d\")}  \n",
    "\n",
    "### Best Params\n",
    "{best_params}\n",
    "\n",
    "### Metrics (Test Set)\n",
    "{json.dumps(metrics, indent=2)}\n",
    "\n",
    "### Objective\n",
    "Optimized for *recall*, minimizing false negatives (e.g., catching as many positive cases as possible).\n",
    "\n",
    "### Notes\n",
    "Educational demo only â€” not medical advice.\n",
    "\"\"\"\n",
    "\n",
    "# 10. Golden Examples\n",
    "golden = []\n",
    "for i in range(min(10, len(X_test))):\n",
    "    row = X_test.iloc[i].to_dict()\n",
    "    golden.append({\n",
    "        \"input\": to_py(row),\n",
    "        \"pred_proba_high\": float(test_proba[i]),\n",
    "        \"label\": int(test_pred[i]),\n",
    "        \"true\": int(y_test[i])\n",
    "    })\n",
    "\n",
    "# 10. Save\n",
    "with open(\"preproc_v1.json\",\"w\") as f: json.dump(to_py(preproc_manifest),f,indent=2)\n",
    "with open(\"dt_model_v1.json\",\"w\") as f: json.dump(to_py(dt_export),f,indent=2)\n",
    "with open(\"model_card_v1.md\",\"w\") as f: f.write(model_card)\n",
    "with open(\"golden_examples_v1.json\",\"w\") as f: json.dump(to_py(golden),f,indent=2)\n",
    "\n",
    "print(\"Artifacts written: preproc_v1_recall.json, dt_model_v1_recall.json, model_card_v1_recall.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ee4c53-5fc2-464f-a350-6ccbb7053222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.7931898368218473, 'pr_auc': 0.391036285507704, 'precision': 0.3092534914096252, 'recall': 0.7710420841683366, 'f1': 0.44144854786661886, 'specificity': 0.6783776197604791, 'confusion_matrix': {'tn': 14501, 'fp': 6875, 'fn': 914, 'tp': 3078}}\n",
      "\n",
      "=== Heart Disease Risk Assessment ===\n",
      "Please enter the following information:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "BMI (typical range: 12.0-95.0):  0\n",
      "MentHlth (typical range: 0.0-30.0):  0\n",
      "PhysHlth (typical range: 0.0-30.0):  0\n",
      "Age (typical range: 1.0-13.0):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HeartDiseaseorAttack options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HeartDiseaseorAttack:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HighBP options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HighBP:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HighChol options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HighChol:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CholCheck options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "CholCheck:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smoker options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Smoker:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stroke options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Stroke:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PhysActivity options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "PhysActivity:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fruits options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Fruits:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Veggies options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Veggies:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HvyAlcoholConsump options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HvyAlcoholConsump:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AnyHealthcare options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "AnyHealthcare:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NoDocbcCost options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NoDocbcCost:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GenHlth options: 1, 2, 3, 4, 5\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "GenHlth:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DiffWalk options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "DiffWalk:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sex options: 0, 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sex:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Education options: 1, 2, 3, 4, 5, 6\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Education:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Income options: 1, 2, 3, 4, 5, 6, 7, 8\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Income:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PREDICTION RESULTS\n",
      "==================================================\n",
      "\n",
      "ðŸ“Š Input Summary:\n",
      "  â€¢ BMI: 0.0\n",
      "  â€¢ MentHlth: 0.0\n",
      "  â€¢ PhysHlth: 0.0\n",
      "  â€¢ Age: 0.0\n",
      "  â€¢ HeartDiseaseorAttack: 0\n",
      "  â€¢ HighBP: 0\n",
      "  â€¢ HighChol: 0\n",
      "  â€¢ CholCheck: 0\n",
      "  â€¢ Smoker: 0\n",
      "  â€¢ Stroke: 0\n",
      "  â€¢ PhysActivity: 0\n",
      "  â€¢ Fruits: 0\n",
      "  â€¢ Veggies: 0\n",
      "  â€¢ HvyAlcoholConsump: 0\n",
      "  â€¢ AnyHealthcare: 0\n",
      "  â€¢ NoDocbcCost: 0\n",
      "  â€¢ GenHlth: 0\n",
      "  â€¢ DiffWalk: 0\n",
      "  â€¢ Sex: 0\n",
      "  â€¢ Education: 0\n",
      "  â€¢ Income: 0\n",
      "\n",
      "ðŸŒ³ Decision Path:\n",
      "  Step 1: HighBP=0 = 1.000 > 0.500\n",
      "          â†’ Go right\n",
      "  Step 2: BMI = 0.000 <= 28.500\n",
      "          â†’ Go left\n",
      "  Step 3: Age = 0.000 <= 8.500\n",
      "          â†’ Go left\n",
      "  Step 4: GenHlth=4 = 0.000 <= 0.500\n",
      "          â†’ Go left\n",
      "  Step 5: GenHlth=5 = 0.000 <= 0.500\n",
      "          â†’ Go left\n",
      "  Step 6: Reached leaf node #36\n",
      "\n",
      "ðŸŽ¯ Prediction:\n",
      "  Probability of heart disease: 10.1%\n",
      "  Threshold: 0.505\n",
      "  Classification: LOW RISK\n",
      "\n",
      "ðŸ“ˆ Model Performance (on test set):\n",
      "  â€¢ Precision: 30.9%\n",
      "  â€¢ Recall: 77.1%\n",
      "  â€¢ F1 Score: 44.1%\n",
      "\n",
      "âš ï¸  DISCLAIMER: This is for educational purposes only.\n",
      "    Please consult healthcare professionals for medical advice.\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Would you like to assess another case? (yes/no):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for using the Heart Disease Risk Assessment tool!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreePredictor:\n",
    "    def __init__(self, preproc_path=\"preproc_v1.json\", model_path=\"dt_model_v1.json\"):\n",
    "        \"\"\"Initialize the predictor with preprocessing and model configs\"\"\"\n",
    "        with open(preproc_path, 'r') as f:\n",
    "            self.preproc = json.load(f)\n",
    "        with open(model_path, 'r') as f:\n",
    "            self.model = json.load(f)\n",
    "        \n",
    "        self.tree = self.model['tree']['nodes']\n",
    "        self.threshold = self.model['threshold']\n",
    "        \n",
    "    def get_user_input(self):\n",
    "        \"\"\"Collect user input for all features\"\"\"\n",
    "        print(\"\\n=== Heart Disease Risk Assessment ===\")\n",
    "        print(\"Please enter the following information:\\n\")\n",
    "        \n",
    "        user_data = {}\n",
    "        \n",
    "        # Collect numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            range_info = self.preproc['numeric_ranges_train'][col]\n",
    "            while True:\n",
    "                try:\n",
    "                    value = input(f\"{col} (typical range: {range_info['min']:.1f}-{range_info['max']:.1f}): \").strip()\n",
    "                    if value == \"\":\n",
    "                        # Use imputation value if empty\n",
    "                        user_data[col] = None\n",
    "                        print(f\"  â†’ Using median value: {self.preproc['numeric_imputation'][col]:.1f}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        user_data[col] = float(value)\n",
    "                        break\n",
    "                except ValueError:\n",
    "                    print(\"  Please enter a valid number or press Enter to use default\")\n",
    "        \n",
    "        # Collect categorical features\n",
    "        for col in self.preproc['categorical']:\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            print(f\"\\n{col} options: {', '.join(str(v) for v in vocab if v is not None)}\")\n",
    "            while True:\n",
    "                value = input(f\"{col}: \").strip()\n",
    "                if value == \"\":\n",
    "                    user_data[col] = None\n",
    "                    print(f\"  â†’ Using most frequent value\")\n",
    "                    break\n",
    "                # Try to convert to appropriate type\n",
    "                try:\n",
    "                    if value.isdigit():\n",
    "                        value = int(value)\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "                except:\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "        \n",
    "        return user_data\n",
    "    \n",
    "    def preprocess_input(self, user_data):\n",
    "        \"\"\"Apply preprocessing to user input\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Process numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            value = user_data.get(col)\n",
    "            if value is None:\n",
    "                # Apply imputation\n",
    "                value = self.preproc['numeric_imputation'][col]\n",
    "            features.append(value)\n",
    "        \n",
    "        # Process categorical features with one-hot encoding\n",
    "        for col in self.preproc['categorical']:\n",
    "            value = user_data.get(col)\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            \n",
    "            # Create one-hot encoding\n",
    "            for category in vocab:\n",
    "                if value == category:\n",
    "                    features.append(1.0)\n",
    "                else:\n",
    "                    features.append(0.0)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def trace_tree(self, features):\n",
    "        \"\"\"Trace through the decision tree and return path\"\"\"\n",
    "        path = []\n",
    "        node_idx = 0  # Start at root\n",
    "        \n",
    "        while True:\n",
    "            node = self.tree[node_idx]\n",
    "            \n",
    "            if node['is_leaf']:\n",
    "                # Reached a leaf node\n",
    "                path.append({\n",
    "                    'node': node_idx,\n",
    "                    'type': 'leaf',\n",
    "                    'values': node['value']\n",
    "                })\n",
    "                break\n",
    "            \n",
    "            # Get feature name for this split\n",
    "            feature_idx = node['feature_index']\n",
    "            feature_info = self.preproc['final_feature_order'][feature_idx]\n",
    "            \n",
    "            # Make decision\n",
    "            feature_value = features[feature_idx]\n",
    "            threshold = node['threshold']\n",
    "            \n",
    "            if feature_value <= threshold:\n",
    "                next_node = node['left']\n",
    "                direction = 'left'\n",
    "                condition = f\"<= {threshold:.3f}\"\n",
    "            else:\n",
    "                next_node = node['right']\n",
    "                direction = 'right'\n",
    "                condition = f\"> {threshold:.3f}\"\n",
    "            \n",
    "            path.append({\n",
    "                'node': node_idx,\n",
    "                'type': 'decision',\n",
    "                'feature': feature_info,\n",
    "                'feature_value': feature_value,\n",
    "                'threshold': threshold,\n",
    "                'direction': direction,\n",
    "                'condition': condition\n",
    "            })\n",
    "            \n",
    "            node_idx = next_node\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def predict(self, features):\n",
    "        \"\"\"Make prediction using the decision tree\"\"\"\n",
    "        # Trace to leaf node\n",
    "        node_idx = 0\n",
    "        while not self.tree[node_idx]['is_leaf']:\n",
    "            node = self.tree[node_idx]\n",
    "            if features[node['feature_index']] <= node['threshold']:\n",
    "                node_idx = node['left']\n",
    "            else:\n",
    "                node_idx = node['right']\n",
    "        \n",
    "        # Get prediction from leaf node\n",
    "        leaf_values = self.tree[node_idx]['value']\n",
    "        # Convert to probability (positive class)\n",
    "        total = sum(leaf_values)\n",
    "        prob_positive = leaf_values[1] / total if total > 0 else 0\n",
    "        \n",
    "        return prob_positive\n",
    "    \n",
    "    def display_results(self, user_data, features, path, prob_positive):\n",
    "        \"\"\"Display the prediction results and decision path\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Show input summary\n",
    "        print(\"\\nðŸ“Š Input Summary:\")\n",
    "        for col, value in user_data.items():\n",
    "            if value is not None:\n",
    "                print(f\"  â€¢ {col}: {value}\")\n",
    "            else:\n",
    "                if col in self.preproc['numeric']:\n",
    "                    print(f\"  â€¢ {col}: {self.preproc['numeric_imputation'][col]:.1f} (imputed)\")\n",
    "                else:\n",
    "                    print(f\"  â€¢ {col}: (imputed)\")\n",
    "        \n",
    "        # Show decision path\n",
    "        print(\"\\nðŸŒ³ Decision Path:\")\n",
    "        for i, step in enumerate(path):\n",
    "            if step['type'] == 'decision':\n",
    "                feature = step['feature']\n",
    "                if feature['kind'] == 'numeric':\n",
    "                    feature_name = feature['source']\n",
    "                else:\n",
    "                    feature_name = f\"{feature['source']}={feature['category']}\"\n",
    "                \n",
    "                print(f\"  Step {i+1}: {feature_name} = {step['feature_value']:.3f} {step['condition']}\")\n",
    "                print(f\"          â†’ Go {step['direction']}\")\n",
    "            else:\n",
    "                print(f\"  Step {i+1}: Reached leaf node #{step['node']}\")\n",
    "        \n",
    "        # Show prediction\n",
    "        print(\"\\nðŸŽ¯ Prediction:\")\n",
    "        print(f\"  Probability of heart disease: {prob_positive:.1%}\")\n",
    "        \n",
    "        prediction = 1 if prob_positive >= self.threshold else 0\n",
    "        risk_level = \"HIGH\" if prediction == 1 else \"LOW\"\n",
    "        \n",
    "        print(f\"  Threshold: {self.threshold:.3f}\")\n",
    "        print(f\"  Classification: {risk_level} RISK\")\n",
    "        \n",
    "        # Show model performance context\n",
    "        print(\"\\nðŸ“ˆ Model Performance (on test set):\")\n",
    "        metrics = self.model['metrics']\n",
    "        print(f\"  â€¢ Precision: {metrics['precision']:.1%}\")\n",
    "        print(f\"  â€¢ Recall: {metrics['recall']:.1%}\")\n",
    "        print(f\"  â€¢ F1 Score: {metrics['f1']:.1%}\")\n",
    "        \n",
    "        print(\"\\nâš ï¸  DISCLAIMER: This is for educational purposes only.\")\n",
    "        print(\"    Please consult healthcare professionals for medical advice.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the predictor\"\"\"\n",
    "    try:\n",
    "        # Initialize predictor\n",
    "        predictor = DecisionTreePredictor()\n",
    "        \n",
    "        while True:\n",
    "            # Get user input\n",
    "            user_data = predictor.get_user_input()\n",
    "            \n",
    "            # Preprocess input\n",
    "            features = predictor.preprocess_input(user_data)\n",
    "            \n",
    "            # Trace decision path\n",
    "            path = predictor.trace_tree(features)\n",
    "            \n",
    "            # Get prediction\n",
    "            prob_positive = predictor.predict(features)\n",
    "            \n",
    "            # Display results\n",
    "            predictor.display_results(user_data, features, path, prob_positive)\n",
    "            \n",
    "            # Ask if user wants to continue\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            again = input(\"\\nWould you like to assess another case? (yes/no): \").strip().lower()\n",
    "            if again not in ['yes', 'y']:\n",
    "                print(\"\\nThank you for using the Heart Disease Risk Assessment tool!\")\n",
    "                break\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find required files. Please ensure 'preproc_v1.json' and 'dt_model_v1.json' exist.\")\n",
    "        print(f\"Details: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(metrics)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "380ae753-a399-4a64-aead-69de6e749a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN model with grid search...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best parameters: {'knn__algorithm': 'auto', 'knn__metric': 'manhattan', 'knn__n_neighbors': 3, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Best cross-validation recall: 0.2572\n",
      "\n",
      "Test Accuracy (default threshold): 0.8187\n",
      "\n",
      "Classification Report (default threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90     21376\n",
      "           1       0.39      0.26      0.31      3992\n",
      "\n",
      "    accuracy                           0.82     25368\n",
      "   macro avg       0.63      0.59      0.60     25368\n",
      "weighted avg       0.79      0.82      0.80     25368\n",
      "\n",
      "\n",
      "--- Adjusted Threshold = 0.2 (Higher Recall) ---\n",
      "Test Accuracy: 0.7048\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80     21376\n",
      "           1       0.29      0.61      0.39      3992\n",
      "\n",
      "    accuracy                           0.70     25368\n",
      "   macro avg       0.60      0.67      0.60     25368\n",
      "weighted avg       0.81      0.70      0.74     25368\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15446  5930]\n",
      " [ 1558  2434]]\n",
      "\n",
      "Simple KNN (k=5) Accuracy: 0.8320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"diabetes_health.csv\")\n",
    "target_col = \"Diabetes\"\n",
    "y = (df[target_col] > 0).astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Split categorical vs numeric\n",
    "categorical_cols, numeric_cols = [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        categorical_cols.append(c)\n",
    "    elif pd.api.types.is_integer_dtype(X[c]):\n",
    "        (categorical_cols if X[c].nunique() <= 10 else numeric_cols).append(c)\n",
    "    else:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "# 2. Train/test split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Preprocessing\n",
    "numeric_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4. Create KNN pipeline\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# 5. Hyperparameter tuning (optimized for recall)\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5],\n",
    "    'knn__weights': ['distance'],\n",
    "    'knn__metric': ['manhattan'],\n",
    "    'knn__p': [1, 2],  # Power parameter for minkowski metric\n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    knn_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='recall',  # Optimizing for recall instead of accuracy\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training KNN model with grid search...\")\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "\n",
    "# 6. Best model\n",
    "best_knn = grid_search.best_estimator_\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation recall: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 7. Evaluate on test set\n",
    "y_pred = best_knn.predict(X_test)\n",
    "y_pred_proba = best_knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Adjust decision threshold to increase recall\n",
    "# Lower values (0.2, 0.25) = Higher recall (catch more diabetes cases, more false positives)\n",
    "# Higher values (0.4, 0.5) = Lower recall but higher precision (fewer false positives)\n",
    "threshold = 0.2  # Adjust this value between 0 and 1\n",
    "y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy (default threshold): {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report (default threshold):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\n--- Adjusted Threshold = {threshold} (Higher Recall) ---\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_adjusted):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_adjusted))\n",
    "\n",
    "# 8. Alternative: Simple KNN without tuning\n",
    "simple_knn = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "simple_knn.fit(X_trainval, y_trainval)\n",
    "simple_pred = simple_knn.predict(X_test)\n",
    "print(f\"\\nSimple KNN (k=5) Accuracy: {accuracy_score(y_test, simple_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b24adf5-42ad-4b4f-b2bc-4924093cdef2",
   "metadata": {},
   "source": [
    "threshold = before  -> after\n",
    "precision = 0.59 -> 0.60\n",
    "recall =    0.68 -> 0.67\n",
    "\n",
    "{'knn__metric': 'manhattan', 'knn__n_neighbors': 5, 'knn__weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74f5a379-013e-4da5-a044-e99a87f219d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__algorithm': 'auto',\n",
       " 'knn__metric': 'manhattan',\n",
       " 'knn__n_neighbors': 3,\n",
       " 'knn__p': 1,\n",
       " 'knn__weights': 'distance'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc954cb8-4697-4a19-9a6f-b3dfed41addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Best parameters: {'knn__algorithm': 'auto', 'knn__metric': 'euclidean', 'knn__n_neighbors': 3, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Best CV recall score: 0.268\n",
      "\n",
      "Artifacts written: preproc_v2.json, knn_model_v2.json, model_card_v2.md, golden_examples_v2.json\n",
      "\n",
      "Test Metrics:\n",
      "  ROC-AUC: 0.685\n",
      "  PR-AUC: 0.284\n",
      "  Precision: 0.290\n",
      "  Recall: 0.626\n",
      "  F1-Score: 0.396\n",
      "  Specificity: 0.714\n",
      "  Threshold: 0.000\n"
     ]
    }
   ],
   "source": [
    "import json, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    confusion_matrix, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Helper\n",
    "def to_py(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    if isinstance(o, dict):\n",
    "        return {str(k): to_py(v) for k, v in o.items()}\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        return [to_py(v) for v in o]\n",
    "    return o\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"diabetes_health.csv\")\n",
    "target_col = \"Diabetes\"\n",
    "y = (df[target_col] > 0).astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Split categorical vs numeric\n",
    "categorical_cols, numeric_cols = [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        categorical_cols.append(c)\n",
    "    elif pd.api.types.is_integer_dtype(X[c]):\n",
    "        (categorical_cols if X[c].nunique() <= 10 else numeric_cols).append(c)\n",
    "    else:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "# 2. Train/test split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Preprocessing (with scaling for KNN)\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4. KNN with GridSearchCV tuned for recall\n",
    "knn = KNeighborsClassifier()\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"knn\", knn)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"knn__weights\": ['distance'],\n",
    "    \"knn__metric\": ['euclidean', 'manhattan', 'minkowski'],\n",
    "    \"knn__p\": [1, 2],\n",
    "    \"knn__algorithm\": ['auto']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV with recall scoring\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=\"recall\", n_jobs=-1, verbose=1\n",
    ")\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_pipe = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "print(f\"Best CV recall score: {grid.best_score_:.3f}\")\n",
    "\n",
    "# 5. Threshold selection â€” maximize recall with precision constraint\n",
    "val_proba = best_pipe.predict_proba(X_trainval)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_trainval, val_proba)\n",
    "\n",
    "# Set minimum precision to 40% to avoid guessing all positive\n",
    "target_min_precision = 0.40\n",
    "mask = prec >= target_min_precision\n",
    "if mask.any():\n",
    "    chosen_idx = np.argmax(rec[mask])  # maximize recall\n",
    "    chosen_threshold = thr[np.where(mask)[0][chosen_idx]]\n",
    "else:\n",
    "    # Fallback: find threshold closest to 40% precision\n",
    "    closest_idx = np.argmin(np.abs(prec - target_min_precision))\n",
    "    chosen_threshold = thr[min(closest_idx, len(thr) - 1)]\n",
    "chosen_threshold = float(chosen_threshold)\n",
    "\n",
    "# 6. Evaluate\n",
    "test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_proba >= chosen_threshold).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "    \"pr_auc\": float(average_precision_score(y_test, test_proba)),\n",
    "    \"precision\": float(precision_score(y_test, test_pred)),\n",
    "    \"recall\": float(recall_score(y_test, test_pred)),\n",
    "    \"f1\": float(f1_score(y_test, test_pred))\n",
    "}\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "metrics[\"specificity\"] = float(tn / (tn + fp + 1e-12))\n",
    "metrics[\"confusion_matrix\"] = {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)}\n",
    "\n",
    "# 7. Export preprocessing artifacts\n",
    "preprocessor.fit(X_trainval)\n",
    "num_imputer = preprocessor.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "num_scaler = preprocessor.named_transformers_[\"num\"].named_steps[\"scaler\"]\n",
    "num_impute_values = {c: float(v) for c, v in zip(numeric_cols, num_imputer.statistics_.tolist())}\n",
    "num_scale_mean = {c: float(v) for c, v in zip(numeric_cols, num_scaler.mean_.tolist())}\n",
    "num_scale_std = {c: float(v) for c, v in zip(numeric_cols, num_scaler.scale_.tolist())}\n",
    "num_ranges = {c: {\"min\": float(X_trainval[c].min()), \"max\": float(X_trainval[c].max())} for c in numeric_cols}\n",
    "\n",
    "onehot = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_vocabs = {}\n",
    "for c, cats in zip(categorical_cols, onehot.categories_):\n",
    "    cat_vocabs[c] = [None if (isinstance(v, float) and math.isnan(v)) else v for v in cats.tolist()]\n",
    "\n",
    "final_feature_order = []\n",
    "for col in numeric_cols:\n",
    "    final_feature_order.append({\"source\": col, \"kind\": \"numeric\"})\n",
    "for col, cats in cat_vocabs.items():\n",
    "    for cat in cats:\n",
    "        final_feature_order.append({\"source\": col, \"kind\": \"onehot\", \"category\": cat})\n",
    "\n",
    "preproc_manifest = {\n",
    "    \"numeric\": numeric_cols,\n",
    "    \"categorical\": categorical_cols,\n",
    "    \"numeric_imputation\": num_impute_values,\n",
    "    \"numeric_scaling_mean\": num_scale_mean,\n",
    "    \"numeric_scaling_std\": num_scale_std,\n",
    "    \"numeric_ranges_train\": num_ranges,\n",
    "    \"categorical_vocabulary\": cat_vocabs,\n",
    "    \"final_feature_order\": final_feature_order,\n",
    "    \"preproc_version\": \"v2_knn_recall\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "\n",
    "# 8. Export KNN model info\n",
    "knn_export = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": chosen_threshold,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_version\": \"v2_knn_recall\",\n",
    "    \"model_type\": \"KNeighborsClassifier\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "    \"cv_best_score\": float(grid.best_score_),\n",
    "    \"note\": \"KNN is instance-based and requires the full training set for predictions\"\n",
    "}\n",
    "\n",
    "# 9. Model Card\n",
    "model_card = f\"\"\"# Diabetes KNN Model (Recall-Prioritized)\n",
    "\n",
    "**Model version:** v2  \n",
    "**Model type:** K-Nearest Neighbors  \n",
    "**Training date:** {datetime.utcnow().strftime(\"%Y-%m-%d\")}  \n",
    "\n",
    "### Best Params (GridSearchCV)\n",
    "{json.dumps(best_params, indent=2)}\n",
    "\n",
    "### Cross-Validation\n",
    "- Best CV Recall Score: {grid.best_score_:.3f}\n",
    "- Stratified 5-Fold CV\n",
    "\n",
    "### Metrics (Test Set)\n",
    "{json.dumps(metrics, indent=2)}\n",
    "\n",
    "### Objective\n",
    "Optimized for *recall* via hyperparameter tuning, minimizing false negatives while maintaining precision above 40%.\n",
    "\n",
    "### Model Details\n",
    "- Hyperparameter tuning with GridSearchCV\n",
    "- Distance weighting for neighbors\n",
    "- Features scaled using StandardScaler\n",
    "- Focused on lower k values (3-11 neighbors)\n",
    "\n",
    "### Notes\n",
    "Educational demo only â€” not medical advice.\n",
    "\"\"\"\n",
    "\n",
    "# 10. Golden Examples\n",
    "golden = []\n",
    "for i in range(min(10, len(X_test))):\n",
    "    row = X_test.iloc[i].to_dict()\n",
    "    golden.append({\n",
    "        \"input\": to_py(row),\n",
    "        \"pred_proba_high\": float(test_proba[i]),\n",
    "        \"label\": int(test_pred[i]),\n",
    "        \"true\": int(y_test[i])\n",
    "    })\n",
    "\n",
    "# 11. Save\n",
    "with open(\"preproc_v2.json\",\"w\") as f: json.dump(to_py(preproc_manifest),f,indent=2)\n",
    "with open(\"knn_model_v2.json\",\"w\") as f: json.dump(to_py(knn_export),f,indent=2)\n",
    "with open(\"model_card_v2.md\",\"w\") as f: f.write(model_card)\n",
    "with open(\"golden_examples_v2.json\",\"w\") as f: json.dump(to_py(golden),f,indent=2)\n",
    "\n",
    "print(\"\\nArtifacts written: preproc_v2.json, knn_model_v2.json, model_card_v2.md, golden_examples_v2.json\")\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  ROC-AUC: {metrics['roc_auc']:.3f}\")\n",
    "print(f\"  PR-AUC: {metrics['pr_auc']:.3f}\")\n",
    "print(f\"  Precision: {metrics['precision']:.3f}\")\n",
    "print(f\"  Recall: {metrics['recall']:.3f}\")\n",
    "print(f\"  F1-Score: {metrics['f1']:.3f}\")\n",
    "print(f\"  Specificity: {metrics['specificity']:.3f}\")\n",
    "print(f\"  Threshold: {chosen_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f6abc33-35d3-405b-b8f2-2dfd70aaf275",
   "metadata": {},
   "source": [
    "Test Metrics:\n",
    "  ROC-AUC: 0.683\n",
    "  PR-AUC: 0.281\n",
    "  Precision: 0.322\n",
    "  Recall: 0.430\n",
    "  F1-Score: 0.368\n",
    "  Specificity: 0.831\n",
    "  Threshold: 0.333"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
